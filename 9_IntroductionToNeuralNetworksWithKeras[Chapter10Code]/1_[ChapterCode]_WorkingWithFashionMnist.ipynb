{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d4434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa039b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530db4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39baa152",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3e81f",
   "metadata": {},
   "source": [
    "# Making first steps with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7a5506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c3c336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80f9f9",
   "metadata": {},
   "source": [
    "### Working with fashion mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327210f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d24bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ba53a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceacdf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260da251",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = X_train_full[5000:]/ 255, X_train_full[:5000]/ 255\n",
    "y_train, y_val = y_train_full[5000:], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba37ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3c8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "something = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca54a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e33c8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de311e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7e8a057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X_train[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91bf9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(X_train[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7743a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d57bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another style of building a model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c54a58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed0af93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x1ba68185a00>,\n",
       " <keras.layers.core.dense.Dense at 0x1ba68185400>,\n",
       " <keras.layers.core.dense.Dense at 0x1ba681853a0>,\n",
       " <keras.layers.core.dense.Dense at 0x1ba681854c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ca2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "428f7534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05823506,  0.01903488,  0.0702835 , ..., -0.01400794,\n",
       "         0.06836139,  0.01715151],\n",
       "       [ 0.06359279,  0.00513747,  0.0449021 , ...,  0.04319575,\n",
       "        -0.04062738, -0.04243384],\n",
       "       [-0.06145194, -0.03084966,  0.04731695, ..., -0.06732507,\n",
       "        -0.03929213,  0.05905983],\n",
       "       ...,\n",
       "       [ 0.0269893 ,  0.05195373,  0.02941363, ...,  0.05136456,\n",
       "        -0.0314528 , -0.02396996],\n",
       "       [-0.07243948, -0.06312531,  0.06648678, ...,  0.05958065,\n",
       "         0.05165708, -0.0702085 ],\n",
       "       [-0.06792101, -0.06918918,  0.03983326, ...,  0.0426705 ,\n",
       "        -0.06552242,  0.01895141]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b65baa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6156f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b26566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6978 - accuracy: 0.7702 - val_loss: 0.5037 - val_accuracy: 0.8282\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4887 - accuracy: 0.8288 - val_loss: 0.4593 - val_accuracy: 0.8404\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4445 - accuracy: 0.8454 - val_loss: 0.4300 - val_accuracy: 0.8538\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4190 - accuracy: 0.8525 - val_loss: 0.4080 - val_accuracy: 0.8630\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3981 - accuracy: 0.8598 - val_loss: 0.3802 - val_accuracy: 0.8706\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3819 - accuracy: 0.8655 - val_loss: 0.3674 - val_accuracy: 0.8702\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3676 - accuracy: 0.8705 - val_loss: 0.3699 - val_accuracy: 0.8718\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3556 - accuracy: 0.8746 - val_loss: 0.3803 - val_accuracy: 0.8660\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3435 - accuracy: 0.8785 - val_loss: 0.3591 - val_accuracy: 0.8766\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3357 - accuracy: 0.8813 - val_loss: 0.3644 - val_accuracy: 0.8658\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3254 - accuracy: 0.8845 - val_loss: 0.3567 - val_accuracy: 0.8752\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.8850 - val_loss: 0.3691 - val_accuracy: 0.8678\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3113 - accuracy: 0.8887 - val_loss: 0.3329 - val_accuracy: 0.8816\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8917 - val_loss: 0.3253 - val_accuracy: 0.8866\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2971 - accuracy: 0.8940 - val_loss: 0.3306 - val_accuracy: 0.8834\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2901 - accuracy: 0.8950 - val_loss: 0.3401 - val_accuracy: 0.8770\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2856 - accuracy: 0.8972 - val_loss: 0.3432 - val_accuracy: 0.8706\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2784 - accuracy: 0.9001 - val_loss: 0.3338 - val_accuracy: 0.8764\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2733 - accuracy: 0.9014 - val_loss: 0.3232 - val_accuracy: 0.8838\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2696 - accuracy: 0.9030 - val_loss: 0.3110 - val_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2644 - accuracy: 0.9047 - val_loss: 0.3115 - val_accuracy: 0.8890\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2595 - accuracy: 0.9069 - val_loss: 0.3120 - val_accuracy: 0.8890\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2547 - accuracy: 0.9081 - val_loss: 0.3122 - val_accuracy: 0.8866\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2502 - accuracy: 0.9109 - val_loss: 0.3201 - val_accuracy: 0.8852\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2462 - accuracy: 0.9118 - val_loss: 0.3181 - val_accuracy: 0.8894\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2419 - accuracy: 0.9126 - val_loss: 0.3024 - val_accuracy: 0.8922\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2375 - accuracy: 0.9150 - val_loss: 0.3095 - val_accuracy: 0.8840\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2343 - accuracy: 0.9154 - val_loss: 0.3027 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2304 - accuracy: 0.9179 - val_loss: 0.3238 - val_accuracy: 0.8802\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2259 - accuracy: 0.9187 - val_loss: 0.3244 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb9836dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6977500915527344,\n",
       "  0.4887480139732361,\n",
       "  0.4444655478000641,\n",
       "  0.41899725794792175,\n",
       "  0.39805930852890015,\n",
       "  0.38192906975746155,\n",
       "  0.36762291193008423,\n",
       "  0.3556273579597473,\n",
       "  0.3434888422489166,\n",
       "  0.33573243021965027,\n",
       "  0.32537639141082764,\n",
       "  0.3185569643974304,\n",
       "  0.31130528450012207,\n",
       "  0.30309662222862244,\n",
       "  0.29712817072868347,\n",
       "  0.29012995958328247,\n",
       "  0.28560131788253784,\n",
       "  0.2784331440925598,\n",
       "  0.2733272314071655,\n",
       "  0.2696070373058319,\n",
       "  0.26441100239753723,\n",
       "  0.2594638764858246,\n",
       "  0.2547295391559601,\n",
       "  0.2501909136772156,\n",
       "  0.24622038006782532,\n",
       "  0.24191761016845703,\n",
       "  0.23748625814914703,\n",
       "  0.2342843860387802,\n",
       "  0.2303992211818695,\n",
       "  0.2259359359741211],\n",
       " 'accuracy': [0.7701636552810669,\n",
       "  0.8287636637687683,\n",
       "  0.8453636169433594,\n",
       "  0.8525272607803345,\n",
       "  0.859818160533905,\n",
       "  0.8654909133911133,\n",
       "  0.8705272674560547,\n",
       "  0.8745636343955994,\n",
       "  0.8784727454185486,\n",
       "  0.8813272714614868,\n",
       "  0.8845090866088867,\n",
       "  0.8850363492965698,\n",
       "  0.8887090682983398,\n",
       "  0.8916545510292053,\n",
       "  0.8940363526344299,\n",
       "  0.8950363397598267,\n",
       "  0.8971636295318604,\n",
       "  0.9000727534294128,\n",
       "  0.9014363884925842,\n",
       "  0.902999997138977,\n",
       "  0.9046909213066101,\n",
       "  0.9069454669952393,\n",
       "  0.9080727100372314,\n",
       "  0.9108545184135437,\n",
       "  0.9118000268936157,\n",
       "  0.9125636219978333,\n",
       "  0.9150182008743286,\n",
       "  0.9154182076454163,\n",
       "  0.9179454445838928,\n",
       "  0.9187454581260681],\n",
       " 'val_loss': [0.5036599636077881,\n",
       "  0.4593043029308319,\n",
       "  0.43000438809394836,\n",
       "  0.4080319404602051,\n",
       "  0.3801700472831726,\n",
       "  0.3674299418926239,\n",
       "  0.3699053227901459,\n",
       "  0.38030096888542175,\n",
       "  0.3591042160987854,\n",
       "  0.36443209648132324,\n",
       "  0.3567090928554535,\n",
       "  0.36908018589019775,\n",
       "  0.33293887972831726,\n",
       "  0.32527801394462585,\n",
       "  0.3305584490299225,\n",
       "  0.3400724232196808,\n",
       "  0.343200147151947,\n",
       "  0.33382925391197205,\n",
       "  0.32324981689453125,\n",
       "  0.3109729588031769,\n",
       "  0.3115442991256714,\n",
       "  0.3119696378707886,\n",
       "  0.3122178018093109,\n",
       "  0.32007598876953125,\n",
       "  0.3180818557739258,\n",
       "  0.30235159397125244,\n",
       "  0.30950939655303955,\n",
       "  0.30266013741493225,\n",
       "  0.32384932041168213,\n",
       "  0.3244082033634186],\n",
       " 'val_accuracy': [0.8281999826431274,\n",
       "  0.840399980545044,\n",
       "  0.8537999987602234,\n",
       "  0.8629999756813049,\n",
       "  0.8705999851226807,\n",
       "  0.870199978351593,\n",
       "  0.8718000054359436,\n",
       "  0.8659999966621399,\n",
       "  0.8766000270843506,\n",
       "  0.8658000230789185,\n",
       "  0.8751999735832214,\n",
       "  0.8677999973297119,\n",
       "  0.881600022315979,\n",
       "  0.8866000175476074,\n",
       "  0.883400022983551,\n",
       "  0.8769999742507935,\n",
       "  0.8705999851226807,\n",
       "  0.8763999938964844,\n",
       "  0.8838000297546387,\n",
       "  0.8863999843597412,\n",
       "  0.8889999985694885,\n",
       "  0.8889999985694885,\n",
       "  0.8866000175476074,\n",
       "  0.885200023651123,\n",
       "  0.8894000053405762,\n",
       "  0.8921999931335449,\n",
       "  0.8840000033378601,\n",
       "  0.8942000269889832,\n",
       "  0.8802000284194946,\n",
       "  0.885200023651123]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04c116f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e0216e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afab4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 69.1385 - accuracy: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69.13848876953125, 0.8425999879837036]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "661cc924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc87c2c6",
   "metadata": {},
   "source": [
    "# Using neural network for regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32998865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32cc11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87950ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9c95826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 0.9236\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0400 - val_loss: 1.3726\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5479\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4670\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4436\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4323\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4434\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.4247\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.4340\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4222\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.4210\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4375\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.4206\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.4327\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.4232\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.4256\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.4216\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4373\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.4180\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.4252\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b043ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 762us/step - loss: 0.3763\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13610aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_hat = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42db83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.429 [2.548921]\n",
      "2.099 [2.3265371]\n",
      "2.059 [2.241061]\n"
     ]
    }
   ],
   "source": [
    "for y1, y2 in zip (y_test[:3], y_hat):\n",
    "    print(y1, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d824f12",
   "metadata": {},
   "source": [
    "# Building a wide and deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd81e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8424d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea44605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1920 - val_loss: 1.3249\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3715 - val_loss: 4.6946\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.3690 - val_loss: 36.0804\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34dd72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed3f49b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78e4c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\python\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\python\\lib\\site-packages (from pydot) (3.0.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaeaf0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\python\\lib\\site-packages (0.20)\n"
     ]
    }
   ],
   "source": [
    "! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2f6827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a257d",
   "metadata": {},
   "source": [
    "# Model with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cc967e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8879e1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2874 - val_loss: 1.1361\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9079 - val_loss: 0.8039\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7363 - val_loss: 0.7175\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6646 - val_loss: 0.6709\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6252 - val_loss: 0.6383\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5932 - val_loss: 0.6089\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.5849\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5445 - val_loss: 0.5654\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5498\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5370\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4994 - val_loss: 0.5282\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4881 - val_loss: 0.5176\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.5100\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.5083\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4975\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4985\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4919\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4484 - val_loss: 0.4905\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4855\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.4857\n",
      "162/162 [==============================] - 0s 805us/step - loss: 0.4471\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_val_A, X_val_B = X_val[:, :5], X_val[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                     validation_data=((X_val_A, X_val_B), y_val))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_hat = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16699b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of multiple outputs model structure\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f42ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9503 - main_output_loss: 0.8696 - aux_output_loss: 1.6765 - val_loss: 0.6681 - val_main_output_loss: 0.5972 - val_aux_output_loss: 1.3062\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6978 - main_output_loss: 0.6419 - aux_output_loss: 1.2012 - val_loss: 0.8118 - val_main_output_loss: 0.7876 - val_aux_output_loss: 1.0298\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7838 - main_output_loss: 0.7687 - aux_output_loss: 0.9193 - val_loss: 0.6003 - val_main_output_loss: 0.5496 - val_aux_output_loss: 1.0570\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5056 - main_output_loss: 0.4557 - aux_output_loss: 0.9545 - val_loss: 0.5264 - val_main_output_loss: 0.4963 - val_aux_output_loss: 0.7980\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4787 - main_output_loss: 0.4502 - aux_output_loss: 0.7353 - val_loss: 0.6094 - val_main_output_loss: 0.5951 - val_aux_output_loss: 0.7383\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5086 - main_output_loss: 0.4873 - aux_output_loss: 0.7005 - val_loss: 0.4816 - val_main_output_loss: 0.4564 - val_aux_output_loss: 0.7082\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4668 - main_output_loss: 0.4506 - aux_output_loss: 0.6120 - val_loss: 0.4740 - val_main_output_loss: 0.4526 - val_aux_output_loss: 0.6665\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - main_output_loss: 0.3900 - aux_output_loss: 0.5814 - val_loss: 0.4672 - val_main_output_loss: 0.4460 - val_aux_output_loss: 0.6578\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3967 - main_output_loss: 0.3781 - aux_output_loss: 0.5644 - val_loss: 0.4573 - val_main_output_loss: 0.4351 - val_aux_output_loss: 0.6568\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3840 - main_output_loss: 0.3656 - aux_output_loss: 0.5504 - val_loss: 0.4606 - val_main_output_loss: 0.4384 - val_aux_output_loss: 0.6602\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3743 - main_output_loss: 0.3558 - aux_output_loss: 0.5406 - val_loss: 0.4571 - val_main_output_loss: 0.4342 - val_aux_output_loss: 0.6630\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3690 - main_output_loss: 0.3506 - aux_output_loss: 0.5347 - val_loss: 0.4589 - val_main_output_loss: 0.4372 - val_aux_output_loss: 0.6547\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3696 - main_output_loss: 0.3522 - aux_output_loss: 0.5265 - val_loss: 0.4516 - val_main_output_loss: 0.4296 - val_aux_output_loss: 0.6498\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3597 - main_output_loss: 0.3417 - aux_output_loss: 0.5217 - val_loss: 0.4778 - val_main_output_loss: 0.4553 - val_aux_output_loss: 0.6800\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3573 - main_output_loss: 0.3394 - aux_output_loss: 0.5182 - val_loss: 0.4587 - val_main_output_loss: 0.4366 - val_aux_output_loss: 0.6580\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3538 - main_output_loss: 0.3363 - aux_output_loss: 0.5118 - val_loss: 0.4594 - val_main_output_loss: 0.4366 - val_aux_output_loss: 0.6650\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3513 - main_output_loss: 0.3340 - aux_output_loss: 0.5065 - val_loss: 0.4605 - val_main_output_loss: 0.4386 - val_aux_output_loss: 0.6573\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3487 - main_output_loss: 0.3316 - aux_output_loss: 0.5026 - val_loss: 0.4479 - val_main_output_loss: 0.4258 - val_aux_output_loss: 0.6469\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3469 - main_output_loss: 0.3302 - aux_output_loss: 0.4977 - val_loss: 0.4688 - val_main_output_loss: 0.4469 - val_aux_output_loss: 0.6654\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3456 - main_output_loss: 0.3290 - aux_output_loss: 0.4951 - val_loss: 0.4454 - val_main_output_loss: 0.4234 - val_aux_output_loss: 0.6438\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - main_output_loss: 0.3278 - aux_output_loss: 0.4940 - val_loss: 0.4482 - val_main_output_loss: 0.4266 - val_aux_output_loss: 0.6425\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3554 - main_output_loss: 0.3401 - aux_output_loss: 0.4930 - val_loss: 0.4514 - val_main_output_loss: 0.4290 - val_aux_output_loss: 0.6524\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3607 - main_output_loss: 0.3438 - aux_output_loss: 0.5129 - val_loss: 0.4636 - val_main_output_loss: 0.4437 - val_aux_output_loss: 0.6419\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3503 - main_output_loss: 0.3355 - aux_output_loss: 0.4829 - val_loss: 0.5323 - val_main_output_loss: 0.5188 - val_aux_output_loss: 0.6539\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - main_output_loss: 0.3308 - aux_output_loss: 0.4833 - val_loss: 0.4572 - val_main_output_loss: 0.4377 - val_aux_output_loss: 0.6331\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3383 - main_output_loss: 0.3231 - aux_output_loss: 0.4748 - val_loss: 0.4634 - val_main_output_loss: 0.4443 - val_aux_output_loss: 0.6359\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3360 - main_output_loss: 0.3210 - aux_output_loss: 0.4707 - val_loss: 0.4446 - val_main_output_loss: 0.4238 - val_aux_output_loss: 0.6310\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3386 - main_output_loss: 0.3242 - aux_output_loss: 0.4687 - val_loss: 0.4578 - val_main_output_loss: 0.4379 - val_aux_output_loss: 0.6375\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3354 - main_output_loss: 0.3208 - aux_output_loss: 0.4661 - val_loss: 0.4502 - val_main_output_loss: 0.4309 - val_aux_output_loss: 0.6232\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3355 - main_output_loss: 0.3214 - aux_output_loss: 0.4624 - val_loss: 0.4524 - val_main_output_loss: 0.4327 - val_aux_output_loss: 0.6301\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=30, \n",
    "                     validation_data=([X_val_A, X_val_B], [y_val, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e7eb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f522789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 996us/step - loss: 0.3612 - main_output_loss: 0.3454 - aux_output_loss: 0.5040\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30dafdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_ped_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd323b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5987172]\n",
      " [1.6680965]\n",
      " [2.0043216]] [[2.1286256]\n",
      " [3.377047 ]\n",
      " [1.7457577]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_main, y_ped_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd37cd7",
   "metadata": {},
   "source": [
    "# Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "567c7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([\"input_A, hidden2\"])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bb949",
   "metadata": {},
   "source": [
    "# Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "380b6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of multiple outputs model structure\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6020b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0027 - main_output_loss: 0.8870 - aux_output_loss: 2.0449 - val_loss: 0.7029 - val_main_output_loss: 0.6460 - val_aux_output_loss: 1.2149\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7785 - main_output_loss: 0.7428 - aux_output_loss: 1.0991 - val_loss: 0.7144 - val_main_output_loss: 0.6715 - val_aux_output_loss: 1.1006\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6180 - main_output_loss: 0.5815 - aux_output_loss: 0.9468 - val_loss: 0.5552 - val_main_output_loss: 0.5145 - val_aux_output_loss: 0.9217\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5179 - main_output_loss: 0.4827 - aux_output_loss: 0.8345 - val_loss: 0.5244 - val_main_output_loss: 0.4961 - val_aux_output_loss: 0.7791\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4881 - main_output_loss: 0.4629 - aux_output_loss: 0.7145 - val_loss: 0.5143 - val_main_output_loss: 0.4897 - val_aux_output_loss: 0.7366\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4566 - main_output_loss: 0.4329 - aux_output_loss: 0.6694 - val_loss: 0.5016 - val_main_output_loss: 0.4782 - val_aux_output_loss: 0.7119\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4456 - main_output_loss: 0.4250 - aux_output_loss: 0.6313 - val_loss: 0.4896 - val_main_output_loss: 0.4668 - val_aux_output_loss: 0.6950\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4307 - main_output_loss: 0.4108 - aux_output_loss: 0.6097 - val_loss: 0.4875 - val_main_output_loss: 0.4657 - val_aux_output_loss: 0.6838\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4349 - main_output_loss: 0.4160 - aux_output_loss: 0.6055 - val_loss: 0.5060 - val_main_output_loss: 0.4852 - val_aux_output_loss: 0.6931\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4177 - main_output_loss: 0.4000 - aux_output_loss: 0.5766 - val_loss: 0.4968 - val_main_output_loss: 0.4761 - val_aux_output_loss: 0.6835\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4126 - main_output_loss: 0.3952 - aux_output_loss: 0.5690 - val_loss: 0.4899 - val_main_output_loss: 0.4685 - val_aux_output_loss: 0.6825\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4169 - main_output_loss: 0.3995 - aux_output_loss: 0.5733 - val_loss: 0.5113 - val_main_output_loss: 0.4897 - val_aux_output_loss: 0.7055\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4215 - main_output_loss: 0.4056 - aux_output_loss: 0.5644 - val_loss: 0.4934 - val_main_output_loss: 0.4724 - val_aux_output_loss: 0.6828\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4029 - main_output_loss: 0.3865 - aux_output_loss: 0.5507 - val_loss: 0.4818 - val_main_output_loss: 0.4602 - val_aux_output_loss: 0.6765\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3986 - main_output_loss: 0.3826 - aux_output_loss: 0.5424 - val_loss: 0.4811 - val_main_output_loss: 0.4588 - val_aux_output_loss: 0.6815\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3982 - main_output_loss: 0.3822 - aux_output_loss: 0.5416 - val_loss: 0.4817 - val_main_output_loss: 0.4600 - val_aux_output_loss: 0.6772\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3946 - main_output_loss: 0.3786 - aux_output_loss: 0.5393 - val_loss: 0.4708 - val_main_output_loss: 0.4492 - val_aux_output_loss: 0.6652\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3871 - main_output_loss: 0.3712 - aux_output_loss: 0.5306 - val_loss: 0.4827 - val_main_output_loss: 0.4607 - val_aux_output_loss: 0.6800\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3857 - main_output_loss: 0.3700 - aux_output_loss: 0.5267 - val_loss: 0.4768 - val_main_output_loss: 0.4558 - val_aux_output_loss: 0.6662\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3807 - main_output_loss: 0.3650 - aux_output_loss: 0.5215 - val_loss: 0.4828 - val_main_output_loss: 0.4631 - val_aux_output_loss: 0.6600\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3888 - main_output_loss: 0.3744 - aux_output_loss: 0.5188 - val_loss: 0.4718 - val_main_output_loss: 0.4493 - val_aux_output_loss: 0.6739\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3850 - main_output_loss: 0.3705 - aux_output_loss: 0.5149 - val_loss: 0.4871 - val_main_output_loss: 0.4635 - val_aux_output_loss: 0.6993\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3764 - main_output_loss: 0.3615 - aux_output_loss: 0.5100 - val_loss: 0.4861 - val_main_output_loss: 0.4658 - val_aux_output_loss: 0.6689\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3964 - main_output_loss: 0.3808 - aux_output_loss: 0.5368 - val_loss: 0.4880 - val_main_output_loss: 0.4644 - val_aux_output_loss: 0.7009\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4231 - main_output_loss: 0.4130 - aux_output_loss: 0.5146 - val_loss: 0.4888 - val_main_output_loss: 0.4697 - val_aux_output_loss: 0.6607\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3737 - main_output_loss: 0.3592 - aux_output_loss: 0.5036 - val_loss: 0.4801 - val_main_output_loss: 0.4595 - val_aux_output_loss: 0.6650\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - main_output_loss: 0.3513 - aux_output_loss: 0.4930 - val_loss: 0.4711 - val_main_output_loss: 0.4505 - val_aux_output_loss: 0.6572\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3773 - main_output_loss: 0.3656 - aux_output_loss: 0.4823 - val_loss: 0.5076 - val_main_output_loss: 0.4886 - val_aux_output_loss: 0.6786\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3762 - main_output_loss: 0.3652 - aux_output_loss: 0.4752 - val_loss: 0.4855 - val_main_output_loss: 0.4682 - val_aux_output_loss: 0.6412\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3709 - main_output_loss: 0.3596 - aux_output_loss: 0.4727 - val_loss: 0.4897 - val_main_output_loss: 0.4710 - val_aux_output_loss: 0.6579\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", \n",
    "                                                save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=30, \n",
    "                     validation_data=([X_val_A, X_val_B], [y_val, y_val]), \n",
    "                     callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "515d4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f8db811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3900 - main_output_loss: 0.3744 - aux_output_loss: 0.5313 - val_loss: 0.4715 - val_main_output_loss: 0.4501 - val_aux_output_loss: 0.6638\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3835 - main_output_loss: 0.3677 - aux_output_loss: 0.5255 - val_loss: 0.4811 - val_main_output_loss: 0.4603 - val_aux_output_loss: 0.6685\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4016 - main_output_loss: 0.3871 - aux_output_loss: 0.5316 - val_loss: 0.4881 - val_main_output_loss: 0.4664 - val_aux_output_loss: 0.6835\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3792 - main_output_loss: 0.3642 - aux_output_loss: 0.5145 - val_loss: 0.4674 - val_main_output_loss: 0.4449 - val_aux_output_loss: 0.6694\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3896 - main_output_loss: 0.3751 - aux_output_loss: 0.5202 - val_loss: 0.7887 - val_main_output_loss: 0.8011 - val_aux_output_loss: 0.6776\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3997 - main_output_loss: 0.3837 - aux_output_loss: 0.5430 - val_loss: 0.4887 - val_main_output_loss: 0.4673 - val_aux_output_loss: 0.6810\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3758 - main_output_loss: 0.3610 - aux_output_loss: 0.5084 - val_loss: 0.4678 - val_main_output_loss: 0.4472 - val_aux_output_loss: 0.6538\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3674 - main_output_loss: 0.3529 - aux_output_loss: 0.4979 - val_loss: 0.4840 - val_main_output_loss: 0.4634 - val_aux_output_loss: 0.6690\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3639 - main_output_loss: 0.3501 - aux_output_loss: 0.4880 - val_loss: 0.4694 - val_main_output_loss: 0.4483 - val_aux_output_loss: 0.6586\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3653 - main_output_loss: 0.3516 - aux_output_loss: 0.4883 - val_loss: 0.4948 - val_main_output_loss: 0.4760 - val_aux_output_loss: 0.6646\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3655 - main_output_loss: 0.3518 - aux_output_loss: 0.4881 - val_loss: 0.4663 - val_main_output_loss: 0.4464 - val_aux_output_loss: 0.6457\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3594 - main_output_loss: 0.3460 - aux_output_loss: 0.4804 - val_loss: 0.4718 - val_main_output_loss: 0.4508 - val_aux_output_loss: 0.6613\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - main_output_loss: 0.3518 - aux_output_loss: 0.4775 - val_loss: 0.4725 - val_main_output_loss: 0.4527 - val_aux_output_loss: 0.6506\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5263 - main_output_loss: 0.4940 - aux_output_loss: 0.8170 - val_loss: 0.5781 - val_main_output_loss: 0.4780 - val_aux_output_loss: 1.4786\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4118 - main_output_loss: 0.3817 - aux_output_loss: 0.6827 - val_loss: 0.4530 - val_main_output_loss: 0.4353 - val_aux_output_loss: 0.6121\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3646 - main_output_loss: 0.3510 - aux_output_loss: 0.4863 - val_loss: 0.5299 - val_main_output_loss: 0.5176 - val_aux_output_loss: 0.6410\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3588 - main_output_loss: 0.3459 - aux_output_loss: 0.4750 - val_loss: 0.4693 - val_main_output_loss: 0.4517 - val_aux_output_loss: 0.6280\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3562 - main_output_loss: 0.3436 - aux_output_loss: 0.4694 - val_loss: 0.4429 - val_main_output_loss: 0.4245 - val_aux_output_loss: 0.6085\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3702 - main_output_loss: 0.3588 - aux_output_loss: 0.4723 - val_loss: 0.4536 - val_main_output_loss: 0.4355 - val_aux_output_loss: 0.6165\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3520 - main_output_loss: 0.3400 - aux_output_loss: 0.4600 - val_loss: 0.4818 - val_main_output_loss: 0.4656 - val_aux_output_loss: 0.6281\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3466 - main_output_loss: 0.3347 - aux_output_loss: 0.4529 - val_loss: 0.4553 - val_main_output_loss: 0.4387 - val_aux_output_loss: 0.6046\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3439 - main_output_loss: 0.3324 - aux_output_loss: 0.4471 - val_loss: 0.4510 - val_main_output_loss: 0.4337 - val_aux_output_loss: 0.6065\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - main_output_loss: 0.3341 - aux_output_loss: 0.4462 - val_loss: 0.4564 - val_main_output_loss: 0.4390 - val_aux_output_loss: 0.6134\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3491 - main_output_loss: 0.3381 - aux_output_loss: 0.4476 - val_loss: 0.4591 - val_main_output_loss: 0.4422 - val_aux_output_loss: 0.6119\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3551 - main_output_loss: 0.3450 - aux_output_loss: 0.4457 - val_loss: 0.4700 - val_main_output_loss: 0.4537 - val_aux_output_loss: 0.6168\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - main_output_loss: 0.3300 - aux_output_loss: 0.4345 - val_loss: 0.4525 - val_main_output_loss: 0.4348 - val_aux_output_loss: 0.6119\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3512 - main_output_loss: 0.3410 - aux_output_loss: 0.4427 - val_loss: 0.4695 - val_main_output_loss: 0.4552 - val_aux_output_loss: 0.5984\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3408 - main_output_loss: 0.3310 - aux_output_loss: 0.4293 - val_loss: 0.4565 - val_main_output_loss: 0.4402 - val_aux_output_loss: 0.6030\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=30, \n",
    "                     validation_data=([X_val_A, X_val_B], [y_val, y_val]), \n",
    "                     callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f463ea0",
   "metadata": {},
   "source": [
    "# Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a245244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3ce56a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df02e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of multiple outputs model structure\n",
    "\n",
    "input_ = keras.layers.Input(shape=X_train[1].shape, name=\"wide_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(hidden1)\n",
    "model = keras.Model(inputs=input_, outputs=output)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "957bbe94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7989 - val_loss: 0.8995\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 2.9832\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.9644 - val_loss: 0.5483\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.5125\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4504\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4423\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3880 - val_loss: 0.4291\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4346\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3790 - val_loss: 0.4242\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3750 - val_loss: 0.4335\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3707 - val_loss: 0.4300\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.4173\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.4185\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3630 - val_loss: 0.4236\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.4247\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.4374\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3568 - val_loss: 0.4186\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.4169\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4351\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3549 - val_loss: 0.4108\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4113\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.4185\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4070\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4138\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3413 - val_loss: 0.4438\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.4096\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3389 - val_loss: 0.4084\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.4098\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.4081\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3320 - val_loss: 0.4147\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                     validation_data=(X_val, y_val), \n",
    "                     callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e34d1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000+1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c70f1",
   "metadata": {},
   "source": [
    "# Fine-Tuning NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3891f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "044d2e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23296\\4087176523.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0364bb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2025 - val_loss: 0.6491\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5814 - val_loss: 0.5769\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.5219 - val_loss: 0.5306\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4992 - val_loss: 0.5579\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.5102 - val_loss: 0.5779\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.5551 - val_loss: 0.7294\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.5812 - val_loss: 0.6496\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.6191 - val_loss: 0.5419\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5014 - val_loss: 0.4786\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.4695\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4664\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4607\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.4198 - val_loss: 0.4539\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.4159 - val_loss: 0.4561\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4148 - val_loss: 0.4536\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4093 - val_loss: 0.4477\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.4066 - val_loss: 0.4502\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4050 - val_loss: 0.4493\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4018 - val_loss: 0.4469\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3990 - val_loss: 0.4453\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.3973 - val_loss: 0.4441\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3950 - val_loss: 0.4400\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3936 - val_loss: 0.4380\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3913 - val_loss: 0.4378\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3894 - val_loss: 0.4378\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3868 - val_loss: 0.4381\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3863 - val_loss: 0.4339\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3834 - val_loss: 0.4299\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3827 - val_loss: 0.4361\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.4305\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3788 - val_loss: 0.4292\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.4323\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3757 - val_loss: 0.4294\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3748 - val_loss: 0.4270\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3738 - val_loss: 0.4283\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3732 - val_loss: 0.4241\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3705 - val_loss: 0.4193\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3695 - val_loss: 0.4263\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3687 - val_loss: 0.4267\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3677 - val_loss: 0.4264\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3665 - val_loss: 0.4202\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3657 - val_loss: 0.4253\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3645 - val_loss: 0.4217\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3634 - val_loss: 0.4228\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3624 - val_loss: 0.4192\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3664 - val_loss: 0.4642\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3894 - val_loss: 0.8523\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.4665 - val_loss: 0.4305\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4287\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3688 - val_loss: 0.4228\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3641 - val_loss: 0.4326\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3631 - val_loss: 0.4236\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3617 - val_loss: 0.4178\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3622 - val_loss: 0.4190\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3591 - val_loss: 0.4159\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3601 - val_loss: 0.4198\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3608 - val_loss: 0.4133\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3567 - val_loss: 0.4167\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3553 - val_loss: 0.4110\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3539 - val_loss: 0.4171\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3567 - val_loss: 0.4163\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3550 - val_loss: 0.4161\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3528 - val_loss: 0.4155\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3544 - val_loss: 0.4169\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.4139\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.4132\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4204\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.4168\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3539 - val_loss: 0.4589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba67fd1460>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ba17cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 754us/step - loss: 0.4235\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BA4DF538B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d2e1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "999e8aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 2.0206 - val_loss: 1.0152\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9654 - val_loss: 0.9902\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7354 - val_loss: 0.6668\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 0.6293\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6016\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5718 - val_loss: 0.5825\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.5638\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.5517\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5433\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.5286\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4986 - val_loss: 0.5236\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4895 - val_loss: 0.5146\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.5075\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.5051\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4986\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4885\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4855\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4800\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4791\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4701\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4725\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4660\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4616\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4594\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4584\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4567\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4558\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4535\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4517\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4497\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.4499\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4449\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4443\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4430\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4439\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4423\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4395\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4411\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4409\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4403\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4401\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4353\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4343\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4335\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4336\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4361\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4332\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.4324\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.4314\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.4296\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4328\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4296\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4320\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4279\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4259\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4303\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.4257\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4248\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.4254\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4271\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4264\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.4211\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4238\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4210\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.4200\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4233\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.4271\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4184\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4173\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.4162\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.4215\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.4166\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.4268\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.4179\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.4178\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.4158\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4163\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4169\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.4281\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.4135\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.4149\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.4138\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.4157\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.4128\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4139\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.4138\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4145\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4113\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.4174\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.4128\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4143\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.4148\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.4149\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.4119\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4116\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.4142\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.4161\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.4201\n",
      "121/121 [==============================] - 0s 689us/step - loss: 0.3473\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1490 - val_loss: 1.2459\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8816 - val_loss: 0.9622\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7643 - val_loss: 0.8629\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7239 - val_loss: 0.8046\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6962 - val_loss: 0.7546\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6740 - val_loss: 0.7188\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6548 - val_loss: 0.6902\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6379 - val_loss: 0.6638\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6442\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6277\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6125\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5851 - val_loss: 0.5995\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 0.5874\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5630 - val_loss: 0.5766\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5526 - val_loss: 0.5663\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5424 - val_loss: 0.5556\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - val_loss: 0.5494\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5396\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5146 - val_loss: 0.5322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5272\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.5222\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.5165\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.5122\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.5087\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4744 - val_loss: 0.5064\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.5037\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4638 - val_loss: 0.4994\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4973\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.4950\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4927\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4914\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4896\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4892\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4854\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4850\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4837\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4825\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4826\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4827\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4810\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4773\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4748\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4753\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4733\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4704\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4722\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4719\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4695\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.4687\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4694\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4616\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4622\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4626\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4589\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4595\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4590\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4626\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.4576\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4525\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4565\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4478\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4498\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.4461\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4430\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4470\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4418\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4409\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4448\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4434\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.4396\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4386\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4417\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.4402\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4378\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4359\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4325\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4352\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.4318\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4329\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.4328\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.4322\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4295\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4326\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4304\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4280\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.4292\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4305\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4277\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4304\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.4271\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.4240\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4287\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.4262\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.4285\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.4248\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.4231\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.4223\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.4263\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.4222\n",
      "121/121 [==============================] - 0s 694us/step - loss: 0.3588\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1288 - val_loss: 0.9773\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8189 - val_loss: 0.7010\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6474 - val_loss: 0.6329\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6039\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.5812\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5557 - val_loss: 0.5662\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5391 - val_loss: 0.5500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5351\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5118 - val_loss: 0.5254\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5001 - val_loss: 0.5144\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4906 - val_loss: 0.5092\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4817 - val_loss: 0.5016\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4956\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4908\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.4851\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4553 - val_loss: 0.4802\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4798\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.4740\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4741\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4699\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4686\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4664\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4633\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4661\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4612\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4588\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4619\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4555\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4539\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4552\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4527\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4502\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4492\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4514\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4453\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4485\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4464\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4459\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4450\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4451\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4435\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4409\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4415\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4397\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4431\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4428\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4401\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4373\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4373\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4369\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4352\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4360\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4361\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.4360\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4355\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4346\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.4326\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.4314\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4327\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4314\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.4335\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4321\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.4292\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.4296\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4308\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4314\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.4313\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4294\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.4283\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4281\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4301\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4293\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.4285\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4276\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4292\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4254\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.4275\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.4252\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.4239\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.4253\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.4274\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.4261\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4243\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.4219\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.4251\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.4226\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.4221\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.4213\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4200\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.4205\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.4237\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.4234\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.4235\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.4229\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.4218\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4210\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4245\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.4209\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.4222\n",
      "121/121 [==============================] - 0s 705us/step - loss: 0.3769\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1845 - val_loss: 1.0773\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0752 - val_loss: 0.7657\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7091 - val_loss: 0.7010\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6671 - val_loss: 0.6695\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6374 - val_loss: 0.6440\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.6193\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5892 - val_loss: 0.5999\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5682 - val_loss: 0.5820\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5668\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5328 - val_loss: 0.5529\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5178 - val_loss: 0.5392\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4922 - val_loss: 0.5182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4808 - val_loss: 0.5098\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4713 - val_loss: 0.5014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4944\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4543 - val_loss: 0.4898\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4476 - val_loss: 0.4816\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.4774\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4734\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4666\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4616\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.4574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4561\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4541\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4520\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4514\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4482\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4414\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4434\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4432\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4399\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4399\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4371\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4358\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4367\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4351\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.4354\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.4323\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.4360\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4314\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.4368\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.4321\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4298\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4294\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.4290\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.4292\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.4275\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4281\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4342\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.4358\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.4270\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.4307\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4277\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.4298\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.4309\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.4289\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4283\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.4304\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.4277\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.4258\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.4265\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.4258\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4261\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4276\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4287\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4247\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4257\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.4249\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.4258\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4225\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4256\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.4241\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4237\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4246\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.4242\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4236\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.4259\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.4221\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.4229\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.4257\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.4249\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4242\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4286\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.4224\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.4255\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.4347\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.4275\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.4305\n",
      "121/121 [==============================] - 0s 735us/step - loss: 0.3344\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3984 - val_loss: 1.2201\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8743 - val_loss: 0.8905\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6976 - val_loss: 0.7845\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6393 - val_loss: 0.7256\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.6850\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.6536\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5614 - val_loss: 0.6244\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5425 - val_loss: 0.5991\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5769\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5108 - val_loss: 0.5579\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.5433\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4856 - val_loss: 0.5305\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4752 - val_loss: 0.5227\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4660 - val_loss: 0.5126\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.5059\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4509 - val_loss: 0.4979\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4924\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4858\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4828\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4794\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4751\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4746\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4724\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4669\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4678\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4642\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4630\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4608\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4568\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4567\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4548\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4531\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.4536\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4497\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4499\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.4485\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4471\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4468\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4457\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4443\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4453\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4426\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.4416\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.4420\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4460\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4408\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4400\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.4419\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4412\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.4434\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4415\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.4413\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4424\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4376\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4388\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.4436\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.4411\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4385\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.4409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.4368\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.4388\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.4419\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.4381\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3581 - val_loss: 0.4385\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.4408\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.4407\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.4392\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.4403\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4390\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.4399\n",
      "121/121 [==============================] - 0s 742us/step - loss: 0.4047\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4737 - val_loss: 1.3984\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0200 - val_loss: 0.8237\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7333 - val_loss: 0.6954\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6461 - val_loss: 0.6490\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6076 - val_loss: 0.6240\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.6092\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - val_loss: 0.5939\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5811\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5694\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5586\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5112 - val_loss: 0.5505\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5003 - val_loss: 0.5396\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.5308\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4803 - val_loss: 0.5238\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4710 - val_loss: 0.5171\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4636 - val_loss: 0.5090\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4559 - val_loss: 0.5023\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4489 - val_loss: 0.4947\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4894\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4820\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4753\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4707\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4676\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4686\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4637\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4578\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4566\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4524\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4488\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4501\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4505\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4426\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4441\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4431\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4395\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.4414\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4358\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4373\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.4398\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4331\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.4361\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4322\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.4317\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.4297\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4295\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4293\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4251\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.4311\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.4297\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.4265\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4270\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.4269\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.4297\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.4233\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.4212\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.4233\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.4210\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.4222\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.4186\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4209\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.4207\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.4196\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4214\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4205\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.4188\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4178\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.4194\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4172\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.4142\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.4148\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.4225\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4147\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.4165\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4118\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.4175\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4167\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.4162\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.4168\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4144\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.4123\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4173\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4102\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.4112\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.4103\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4087\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.4073\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.4089\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.4157\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.4127\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.4113\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.4054\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.4087\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.4091\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.4102\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.4069\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.4107\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.4051\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.4040\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 773us/step - loss: 0.3609\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3438 - val_loss: 0.7656\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6784 - val_loss: 0.6569\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6001\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5679\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5372\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5024 - val_loss: 0.5206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4831 - val_loss: 0.5005\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4945\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4852\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.4825\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.5055\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4842\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4761\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4814\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.5269\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4852\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.4726\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4922\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4907\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4745\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4518 - val_loss: 0.4860\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.4703\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.5031\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4768\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4704\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4725\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4825\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4650\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4730\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4350 - val_loss: 0.4712\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 0.4886\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4668\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4759\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4622\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.4797\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4701\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4650\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4695\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4659\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4886\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4692\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4652\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4927\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.4784\n",
      "121/121 [==============================] - 0s 601us/step - loss: 0.4122\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0427 - val_loss: 0.5976\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5295\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4831 - val_loss: 0.5128\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.5063\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.5038\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4919\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4913\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4946\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4872\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4470 - val_loss: 0.4802\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4808\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4882\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4830\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4829\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4779\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4767\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4774\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.4334 - val_loss: 0.4786\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4728\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4722\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4721\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4306 - val_loss: 0.4699\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4291 - val_loss: 0.4788\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4683\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4770\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4651\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4870\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4696\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4869\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4653\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4260 - val_loss: 0.4695\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4248 - val_loss: 0.4699\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4641\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4663\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4665\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4640\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4221 - val_loss: 0.4648\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4661\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4624\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.4681\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4202 - val_loss: 0.4637\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4690\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4710\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.4635\n",
      "121/121 [==============================] - 0s 634us/step - loss: 0.4322\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4235 - val_loss: 0.7894\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6799 - val_loss: 0.6729\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6015 - val_loss: 0.6097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5665\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5135 - val_loss: 0.5361\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4857 - val_loss: 0.5098\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4968\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.4805\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4390 - val_loss: 0.4856\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4323 - val_loss: 0.4671\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4720\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4283 - val_loss: 0.4718\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4645\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4761\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4712\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4681\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4146 - val_loss: 0.4595\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4570\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4775\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4605\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4639\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4617\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4093 - val_loss: 0.4617\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4506\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4506\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4532\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4506\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4526\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4588\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.4589\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4523\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4559\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4585\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4790\n",
      "121/121 [==============================] - 0s 631us/step - loss: 0.4473\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.4200 - val_loss: 0.7715\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1494 - val_loss: 1.5566\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9319 - val_loss: 0.7147\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5827 - val_loss: 0.7501\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6520 - val_loss: 1.4257\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7493 - val_loss: 0.4722\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4528\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.4396\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4468\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.4508\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.4279\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.4514\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.4483\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.4433\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.4312\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.4622\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4615\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.4499\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.4522\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.4318\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.4544\n",
      "121/121 [==============================] - 0s 765us/step - loss: 0.3194\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0388 - val_loss: 0.6692\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5587\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 0.5211\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4669 - val_loss: 0.5236\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.4738\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4651\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4610\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4675\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.5731\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4369\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4457\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4351\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4247\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.4228\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.4208\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4179\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4180\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4156\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3464 - val_loss: 0.4245\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.4292\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.4176\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.4161\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4203\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.4096\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.4311\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.4486\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.4595\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.4199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.4253\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.4285\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.4236\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.4302\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4329\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.4232\n",
      "121/121 [==============================] - 0s 803us/step - loss: 0.3694\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.9944 - val_loss: 0.8782\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9297 - val_loss: 0.6625\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 0.5381\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4781\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4222 - val_loss: 0.4639\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4530\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.5002\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4424\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.4357\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4362\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.4331\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.4295\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.4341\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.4256\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4313\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.4240\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4181\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.4236\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.4214\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4188\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.4227\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4226\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.4268\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.4203\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.4196\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.4194\n",
      "121/121 [==============================] - 0s 723us/step - loss: 0.3546\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.9731 - val_loss: 0.8597\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8381 - val_loss: 0.7612\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7205 - val_loss: 0.7270\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6847 - val_loss: 0.6980\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6546 - val_loss: 0.6744\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6307 - val_loss: 0.6519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6341\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 0.6162\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.6016\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5868\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.5755\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.5644\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5179 - val_loss: 0.5558\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5465\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.5364\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.5292\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.5229\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.5147\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.5101\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.5036\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4976\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4947\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4899\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4828\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4806\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4785\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4750\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4696\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.4675\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4659\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4617\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4616\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4561\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4571\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4531\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4524\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4492\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.4473\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4439\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4444\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4437\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4408\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.4418\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4394\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.4388\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4389\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4368\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.4360\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.4347\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.4348\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.4344\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4317\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4319\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.4317\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4301\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4311\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4299\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.4269\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.4293\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4293\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4294\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.4278\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.4291\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.4275\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.4274\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.4266\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4266\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.4250\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.4243\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.4243\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.4247\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.4247\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.4254\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.4251\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.4240\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.4260\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.4277\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.4240\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4209\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4230\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.4221\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.4205\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.4238\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.4234\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.4198\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4229\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.4213\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4218\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4217\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.4222\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4195\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.4213\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.4205\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.4192\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.4215\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.4210\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.4216\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.4213\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.4187\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4175\n",
      "121/121 [==============================] - 0s 791us/step - loss: 0.3431\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6234 - val_loss: 1.1535\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8300 - val_loss: 0.9256\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7147 - val_loss: 0.8350\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6627 - val_loss: 0.7656\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6247 - val_loss: 0.7157\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5944 - val_loss: 0.6744\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5693 - val_loss: 0.6401\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5481 - val_loss: 0.6137\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.5899\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5153 - val_loss: 0.5697\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4906 - val_loss: 0.5377\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4808 - val_loss: 0.5264\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.5148\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4645 - val_loss: 0.5047\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 0.4962\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4901\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4840\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4783\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4754\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4733\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4659\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4631\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4617\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4597\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4569\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4548\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4539\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4538\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4523\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4528\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4496\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4514\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4488\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4505\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.4475\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4462\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.4436\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4434\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4424\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4437\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4402\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4408\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4404\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4435\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.4388\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4406\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4400\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4375\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.4395\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4372\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4350\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4353\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.4340\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.4335\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4312\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.4368\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4342\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4344\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.4305\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.4314\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.4331\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4289\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4269\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.4307\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.4291\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.4259\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.4258\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.4262\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.4264\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.4248\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.4284\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.4253\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.4230\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.4215\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.4245\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.4234\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.4216\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.4219\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.4233\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.4227\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.4244\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4217\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4225\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4223\n",
      "121/121 [==============================] - 0s 706us/step - loss: 0.3565\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.3130 - val_loss: 0.8768\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7273 - val_loss: 0.7094\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6523 - val_loss: 0.6735\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6460\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 0.6226\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.6013\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5461 - val_loss: 0.5826\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5285 - val_loss: 0.5658\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5122 - val_loss: 0.5508\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4977 - val_loss: 0.5376\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4846 - val_loss: 0.5271\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.5143\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.5063\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4543 - val_loss: 0.4986\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4858\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4839\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4749\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4702\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4676\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.4636\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4622\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4573\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4566\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4509\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4502\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.4493\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4478\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4476\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4465\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4454\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4435\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4408\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4404\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4429\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4414\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.4405\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4392\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.4366\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4374\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.4354\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4371\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.4374\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4380\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4353\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4349\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.4327\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.4319\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.4316\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4335\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.4319\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.4324\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.4342\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.4321\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.4319\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4298\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.4301\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.4313\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.4318\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.4339\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4281\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.4288\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.4274\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.4294\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.4307\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4282\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4279\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.4272\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4296\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4310\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4307\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.4290\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.4282\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4280\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.4283\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4276\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4297\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.4294\n",
      "121/121 [==============================] - 0s 635us/step - loss: 0.3728\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8114 - val_loss: 10.4870\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 61.3395 - val_loss: 422.4859\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 250.0023 - val_loss: 15867.4814\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 52676.3477 - val_loss: 677085.5000\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 994us/step - loss: 4069684.0000 - val_loss: 23945620.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 11539149.0000 - val_loss: 940339264.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 7367352832.0000 - val_loss: 36355260416.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 122445283328.0000 - val_loss: 1407624282112.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 10346672685056.0000 - val_loss: 54342207930368.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 66460235857920.0000 - val_loss: 2113779026362368.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 1818330373554176.0000 - val_loss: 81506393240109056.0000\n",
      "121/121 [==============================] - 0s 647us/step - loss: 1970902644293632.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0290 - val_loss: 0.9354\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.5389 - val_loss: 0.9593\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5152 - val_loss: 0.9890\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5261 - val_loss: 1.0507\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.5044 - val_loss: 1.0355\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5020 - val_loss: 1.0514\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5041 - val_loss: 1.2079\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5198 - val_loss: 1.0705\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.5073 - val_loss: 1.0915\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5042 - val_loss: 1.0511\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 1.0454\n",
      "121/121 [==============================] - 0s 636us/step - loss: 2.2607\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4352 - val_loss: 10.6097\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 13.5478 - val_loss: 472.2493\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 3255.1189 - val_loss: 25932.2695\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 152148.5938 - val_loss: 1415165.1250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 8504146.0000 - val_loss: 77431640.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 91300520.0000 - val_loss: 4254876160.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 16516363264.0000 - val_loss: 229013700608.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 264251310080.0000 - val_loss: 12590520467456.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 30416161472512.0000 - val_loss: 691952517382144.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1068205544046592.0000 - val_loss: 37809649373675520.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 48100060302409728.0000 - val_loss: 2087027825780457472.0000\n",
      "121/121 [==============================] - 0s 629us/step - loss: 124811972960059392.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3048 - val_loss: 0.7348\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6920 - val_loss: 0.6900\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6423\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6375 - val_loss: 0.5617\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5021 - val_loss: 0.5158\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4908\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4736\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4604\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4561\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4514\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4497\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.4447\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4376\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.4397\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.4314\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.4354\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4258\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.4359\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.4341\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.4349\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.4235\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.4189\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4179\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.4234\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.4216\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.4232\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4283\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.4193\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.4158\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4178\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.4127\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.4148\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4228\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4197\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.4246\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.4135\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.4193\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.4103\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4165\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.4139\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.4187\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.4086\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.4172\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.4073\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.4095\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.4218\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.4152\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.4295\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.4013\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4054\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4132\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.4019\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.4059\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.4035\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.4118\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.4145\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.4130\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.4116\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.4162\n",
      "121/121 [==============================] - 0s 730us/step - loss: 0.3175\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1267 - val_loss: 0.7000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6215 - val_loss: 0.5958\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5518 - val_loss: 0.5495\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.5023\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4840\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4689\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4529\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4519\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4442\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4515\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4405\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4432\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.4327\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.4353\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.4282\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4255\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4335\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.4313\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.4222\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4235\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4194\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.4231\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.4259\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.4213\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4132\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.4208\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.4134\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.4395\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.4101\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.4308\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.4275\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.4228\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.4294\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.4289\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.4336\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.4203\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.4239\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.4311\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.4272\n",
      "121/121 [==============================] - 0s 733us/step - loss: 0.3359\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0758 - val_loss: 0.8214\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6608 - val_loss: 0.6250\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5548\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.5360\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.5180\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4751\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4727\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.4716\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4529\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4484\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.4388\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.4536\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.4429\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4404\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.4528\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.4325\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.4353\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.4376\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.4287\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.4334\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4485\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.4357\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3356 - val_loss: 0.4202\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4211\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.4179\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.4133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.4201\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.4155\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.4141\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.4175\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.4252\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3228 - val_loss: 0.4176\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.4134\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.4098\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.4165\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.4230\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.4170\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.4290\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.4367\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.4152\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.4114\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.4128\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.4166\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.4116\n",
      "121/121 [==============================] - 0s 731us/step - loss: 0.3365\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 1.1807\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4579 - val_loss: 1.5402\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4738 - val_loss: 0.5539\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.5713\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.5042\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.5142\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4856\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.4646\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.4784\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.4645\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.4666\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.4576\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.4744\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.4690\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4629\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4513\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.4398\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.4359\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.4494\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.4600\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.4425\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.4588\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4484\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.4436\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.4844\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.4416\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4915\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.4389\n",
      "121/121 [==============================] - 0s 650us/step - loss: 0.3221\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7158 - val_loss: 0.6114\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.5596\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.5349\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.5067\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4930\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4451\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4366\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4424\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4361\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4384\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4253\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.4482\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4536\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4846\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4522\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4911\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.4584\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.4657\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.4426\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4609\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.4406\n",
      "121/121 [==============================] - 0s 678us/step - loss: 0.4036\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7579 - val_loss: 0.7208\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3354 - val_loss: 1.8147\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0681 - val_loss: 0.7185\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.5621\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.5107\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4693\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.4637\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4750\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4610\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.5004\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4551\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.4673\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.4532\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.4570\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.5801\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.4375\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.4359\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.4472\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.4260\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4418\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.4490\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.4509\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.4211\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.4598\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4570\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.4580\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.4672\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.4378\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4263\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.4343\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.4448\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.6961\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.4422\n",
      "121/121 [==============================] - 0s 656us/step - loss: 0.3603\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2018 - val_loss: 0.6389\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.6655 - val_loss: 0.7371\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.6211 - val_loss: 1.1922\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 2.6116 - val_loss: 13.2245\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 16.2866 - val_loss: 170.1217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 462.5867 - val_loss: 2424.9973\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2161.2842 - val_loss: 34397.9336\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 35898.3203 - val_loss: 487068.0938\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1199259.8750 - val_loss: 6830975.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 16638154.0000 - val_loss: 96886664.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 93003024.0000 - val_loss: 1396906496.0000\n",
      "121/121 [==============================] - 0s 592us/step - loss: 36174216.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7881 - val_loss: 1.2233\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 1.1870\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5672 - val_loss: 1.1352\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5403 - val_loss: 1.1108\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 1.1765\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.5144 - val_loss: 1.0988\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5080 - val_loss: 1.0920\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5082 - val_loss: 1.0999\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4999 - val_loss: 1.0812\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.5015 - val_loss: 1.0889\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5000 - val_loss: 1.0819\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5003 - val_loss: 1.0897\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4988 - val_loss: 1.0741\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.5063 - val_loss: 1.0810\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4990 - val_loss: 1.0796\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.5034 - val_loss: 1.0723\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.4994 - val_loss: 1.0844\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5007 - val_loss: 1.0824\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5006 - val_loss: 1.1014\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4991 - val_loss: 1.0679\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.5021 - val_loss: 1.0727\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5009 - val_loss: 1.0780\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5001 - val_loss: 1.0601\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 1.0744\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 1.0626\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5009 - val_loss: 1.0767\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 1.0754\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5008 - val_loss: 1.0908\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.5008 - val_loss: 1.0768\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5029 - val_loss: 1.0762\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5001 - val_loss: 1.0744\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.5000 - val_loss: 1.0965\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5015 - val_loss: 1.0792\n",
      "121/121 [==============================] - 0s 643us/step - loss: 2.3518\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3346 - val_loss: 1.5016\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 3.3277 - val_loss: 15.7040\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 36.6362 - val_loss: 245.1864\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 513.9357 - val_loss: 4115.0630\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4168.1382 - val_loss: 68509.4844\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 67971.4453 - val_loss: 1145084.3750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 2807131.0000 - val_loss: 18855652.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 48397352.0000 - val_loss: 311981696.0000\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 391197312.0000 - val_loss: 5179602944.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5090641920.0000 - val_loss: 86768312320.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 186355384320.0000 - val_loss: 1427642908672.0000\n",
      "121/121 [==============================] - 0s 648us/step - loss: 85504417792.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8793 - val_loss: 0.5772\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - val_loss: 0.4844\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8340 - val_loss: 0.4939\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4628\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.5399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.9839\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2994 - val_loss: 0.6890\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 739us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6550 - val_loss: 0.5218\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4260\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.4555\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.4524\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.4143\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4318\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.4380\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.4089\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.4124\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.4223\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.4076\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.4433\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.4433\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.4723\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.4351\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.4103\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.4341\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.4384\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.4589\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.4184\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.4110\n",
      "121/121 [==============================] - 0s 737us/step - loss: 0.3332\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.5969\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6570 - val_loss: 0.4469\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4740\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5219\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4397\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4355\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.4401\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.4604\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.4142\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.4222\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.4218\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.4125\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3920\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.3980\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.4293\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3062 - val_loss: 0.3939\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.4389\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.4068\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.4350\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.4437\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.4058\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.4127\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.3833\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.4236\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.3802\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.3656\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.4176\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.4025\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.4491\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.3834\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.4054\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.3890\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.3837\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.3753\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.3670\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2737 - val_loss: 0.4070\n",
      "121/121 [==============================] - 0s 742us/step - loss: 0.3254\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-3.60978613e-01 -3.66689622e-01 -4.30558999e-01 -3.47790221e-01\n",
      " -3.57461433e-01 -4.22609585e+16 -3.29970549e-01 -3.62018824e-01\n",
      " -2.85135307e+10             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2067 - val_loss: 0.6954\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6042\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.5509\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.5097\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4786\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4620\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.4503\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.4466\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.4450\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.4430\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.4541\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4399\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4402\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.4357\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.4445\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4308\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.4254\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.4280\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.4303\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.4255\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.4229\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.4192\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.4210\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.4181\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.4131\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.4175\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.4253\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.4140\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.4235\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.4228\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.4236\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4121\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3998\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.4159\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.4008\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.4089\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.4042\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.4054\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.4163\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.4033\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.4068\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3952\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3989\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.4037\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.4064\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.4061\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.4136\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3998\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.4011\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.4127\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.4020\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.4001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BA64BC5A30&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BA70F3DC10&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BA64BC5A30&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BA70F3DC10&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BA64BC5A30&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BA64BC5A30&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001BA64BC5A30>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BA70F3DC10>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bfbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
